---
title: "Tarea 07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Tarea 07
# Validacion de modelos

# Estudiante
* Merian Herrera Fuentes
* meryann68@gmail.com
* 207180364

```{r warning=FALSE, echo=FALSE}
library(caret)
library(caTools)
library(class)
library(corrplot)
library(dplyr)
library(e1071)
library(ggplot2)
library(lattice)
library(neuralnet)
library(randomForest)
library(readr)
library(ROCR)
library(rpart)
library(rpart.plot)
```

# 1. Analisis del Problema
 
 Los datos se obtienen mediante el  parte oficial de transito que realiza la Direccion General de Policia de Transito al presentarse un accidente, los cuales ingresan a la base de datos de dos formas (hand held y papel). Debido a que parte de la labor principal de la Institucion es salvar vidas, y por los recursos limitados que existen, se trabaja solo con accidentes con heridos y/o fallecidos; y no se trabaja con accidentes que presentan solo datos materiales. Ademas, posteriormente inicia el proceso de limpieza, correccion de inconsistencias, validacion de algunas variables,  georeferenciacion de los accidentes, entre otros. <br><br>

Accidente con victima se refiere cuando en el accidente de transito al menos uno de los participantes resulto: herido leve, grave o fallecido. <br><br>

Para mas informacion revisar la metodologia del documento Memoria estadistica de accidentes de transito con victimas.Periodo 2012-2014. <br><br>

Fuente del dataset:
http://datosabiertos.csv.go.cr/dashboards/19683/accidentes/

# 2. Cargue el archivo nombre.csv en una variable

```{r}
datos_headers = c("id", "rol", "tipo_de_lesion", "edad", "edad_quinquenal", "sexo", "anno", "mes", "dia", "provincia", "canton", "distrito", "dia_1", "mes_1", "edad_quinquenal_1")

datos <- read.csv("datos-transito.csv", 
                  encoding = "UTF-8", 
                  col.names = datos_headers)

head(datos, 80000)
```


```{r}
datos$asistencia_medica <-  as.integer(with(datos, ifelse(datos$tipo_de_lesion %in% c("Herido leve", "Herido grave", "Muerte"), "si", "no")))

drops <- c("id", "tipo_de_lesion", "edad", "dia_1", "mes_1", "edad_quinquenal_1")
datos <- datos[ , !(names(datos) %in% drops)]

head(datos)
```


# 3. Desarolle el Entendimiento de los Datos

#### Valores nulos

```{r}
sapply(datos, function(x) {sum(is.na(x))})
```

#### Variables

- **Rol: ** Este es el role de la persona que participo en el accidente. Variable categorica, posibles valores:

```{r}
datos %>% 
  group_by(rol) %>% 
  summarise(count = n()) 
```

- **Tipo de lesion: ** Tipo de lesion sufrida por la persona que ha tenido el accidente. Variable categorica, posibles valores:

```{r}
datos %>% 
  group_by(asistencia_medica) %>% 
  summarise(count = n()) 
```

- **Edad Quinquenal: **

```{r}
datos %>% 
  group_by(edad_quinquenal) %>% 
  summarise(count = n()) 
```

- **Sexo: ** Sexo de la victima del accidente. Variable categorica, posibles valores:

```{r}
datos %>% 
  group_by(sexo) %>% 
  summarise(count = n()) 
```

- **Anno: ** Anno en el que sucedio en el accidente. Variable numerica, posibles valores:

```{r}
datos %>% 
  group_by(anno) %>% 
  summarise(count = n()) 
```

- **Mes: ** Mes en el que sucedio el accidente. Variable categorica, posibles valores:

```{r}
datos %>% 
  group_by(mes) %>% 
  summarise(count = n()) 
```

- **Dia: ** Dia de la semana en que sucedio el accidente.Variable categorica, posibles valores:

```{r}
datos %>% 
  group_by(dia) %>% 
  summarise(count = n()) 
```

- **Provincia: ** Provincia en la que sucedio el accidente. Variable categorica, posibles valores:

```{r}
datos %>% 
  group_by(provincia) %>% 
  summarise(count = n()) 
```

- **Canton: ** Canton donde sucedio el accidente.Variable categorica, posibles valores:

```{r}
datos %>% 
  group_by(canton) %>% 
  summarise(count = n()) 
```

- **Distrito: ** Distrito donde sucedio el accidente. Variable categorica, posibles valores:

```{r}
datos %>% 
  group_by(distrito) %>% 
  summarise(count = n())
```

```{r}
glimpse(datos)
```

# 4. Utilizando barplot cree un grafico de los atributos del dataset, observe las correlaciones entre atributos

```{r}
provincia_sexo  <- datos %>% 
  group_by(provincia, sexo) %>% 
  summarise(count = n()) 

ggplot(data = provincia_sexo, aes(x = provincia, y = count, fill = sexo)) +
  geom_bar(stat = "identity")
```

```{r}
datos_provincia  <- datos %>% 
  group_by(rol, asistencia_medica) %>% 
  summarise(count = n()) 

ggplot(data = datos_provincia, aes(x = rol, y = count, fill = asistencia_medica)) +
  geom_bar(stat = "identity")
```

```{r}
datos_mes  <- datos %>% 
  group_by(mes, asistencia_medica) %>% 
  summarise(count = n()) 

ggplot(data = datos_mes, aes(x = mes, y = count, fill = asistencia_medica)) +
  geom_bar(stat = "identity")

```

# 5. Realice al menos 5 modelos de los observados en clase

#### Dividir los datos

```{r}
set.seed(12)
split_data <- sample.split(datos$asistencia_medica, SplitRatio = 0.7)

datos_entrenamiento <- datos[split_data,]
datos_prueba <- datos[!split_data,]
```

```{r}
barplot(table(datos_entrenamiento$asistencia_medica), main = 'Distribuci贸n de las clases en los Datos de Entrenamiento', ylab = 'Observaciones', xlab = 'Clase')

barplot(table(datos_prueba$asistencia_medica), main = 'Distribuci贸n de las clases en los Datos de Prueba', ylab = 'Observaciones', xlab = 'Clase')
```


#### KNN

La funcion **knn()** funciona solo con variables numericas, al tener un dataset de practicamente solo variables categoricas, no podemos correr este modelo con el dataset asignado.

#### SVN

```{r}
modelo_svn <- svm(asistencia_medica ~ sexo + rol + provincia, 
                  data = datos_entrenamiento, 
                  kernel = 'linear',
                  cross = 2, 
                  scale = FALSE)
summary(modelo_svn)
```

#### Red Neuronal

```{r}
matriz_dummies <- model.matrix( 
   ~sexo + rol + provincia + asistencia_medica,
   datos_entrenamiento
)

modelo_red_neuronal <- neuralnet(asistencia_medicasi ~ sexoHombre + sexoMujer + rolConductor + rolMotociclista ,
                                 data = matriz_dummies,
                                 hidden = 4,
                                 rep = 1,
                                 linear.output = T)

plot(modelo_red_neuronal, rep = "best")
```


#### Arbol de Decision

```{r}
modelo_arbol <- rpart(asistencia_medica ~ sexo + rol + provincia, 
                      data = datos_entrenamiento, 
                      method =  'class', 
                      control = rpart.control(cp = 0))

rpart.plot(modelo_arbol,
           shadow.col = "gray", 
           main = "Clasificacion de accidentes. Necesita o no asistencia medica")
```

#### Regresion Logistica

```{r}
modelo_regresion_logistica <- glm(asistencia_medica ~ sexo + rol + provincia,
                                   data = datos_entrenamiento,
                                   family = binomial)

summary(modelo_regresion_logistica)
```

#### Bosques Aleatorios

```{r}
modelo_bosque_aleatorio <- randomForest(asistencia_medica ~ sexo + rol + provincia, 
                                        data = datos_entrenamiento)

modelo_bosque_aleatorio
```


# 6. Evaluacion de los modelos


#### SVN

```{r}
datos_prueba$prediccion <- predict(modelo_svn, 
                                   newdata = datos_prueba)

#hist(datos_prueba$asistencia_medica - datos_prueba$prediccion,
#     breaks = 50,
#     main = 'Distribuci贸n de los Residuos en Prueba',
#     xlab = 'residuos')

#plot(y = datos_prueba$asistencia_medica - datos_prueba$prediccion,
#     x = datos_prueba$asistencia_medica ,
#     main = 'Distribuci贸n de los residuos por asistencia medica',
#     xlab = 'Asistencia Medica',
#     ylab = 'residuos')
```

#### Red Neuronal

```{r}
predicciones_red <- neuralnet::compute(modelo_red_neuronal,
                                       mp[,c("V1b","V2")])

results <- data.frame(actual = mp, prediction = predicciones.red$net.result)
results

predicciones.redClass=ifelse(predicciones.red$net.result>=0.5,1,0)
predicciones.redClass
```

#### Arbol de Decision

```{r}
predicciones_arbol <- predict(modelo_arbol, 
                              newdata = datos_prueba, 
                              type = 'class')

# Comparar la etiqueta verdadera contra la etiqueta predicha.
comparacion_arbol <- table(predicciones_arbol, datos_prueba$asistencia_medica)
print(comparacion_arbol)

verdaderos_positivos_arbol <- comparacion_arbol[2,2]
verdaderos_negativos_arbol <- comparacion_arbol[1,1]
falsos_positivos_arbol <- comparacion_arbol[1,2]
falsos_negativos_arbol <- comparacion_arbol[2,1]

# VP+VN / Total
exactitud_arbol <- (verdaderos_positivos_arbol + verdaderos_negativos_arbol) / sum(comparacion_arbol)

# VP / total positivos
sensibilidad_arbol <- verdaderos_positivos_arbol / (verdaderos_positivos_arbol + falsos_negativos_arbol)

# VP / Total clasificados positivos
precision_arbol <- verdaderos_positivos_arbol / (verdaderos_positivos_arbol + falsos_positivos_arbol )

# VN/ Total Negativos
especificidad_arbol <- verdaderos_negativos_arbol / (verdaderos_negativos_arbol + falsos_positivos_arbol)

paste("* Exactitud Total del modelo Arbol de decision: ", round(exactitud_arbol * 100, digits = 0), "%")
paste("* Sensibilidad del modelo Arbol de decision: ", round(sensibilidad_arbol * 100, digits = 0), "%")
paste("* Precision del modelo Arbol de decision: ", round(precision_arbol * 100, digits = 0), "%")
paste("* Especificidad del modelo Arbol de decision: ", round(especificidad_arbol * 100, digits = 0), "%")
```

#### Regresion Logistica

```{r}
predicciones_regresion_logistica <- predict(modelo_regresion_logistica, 
                                            newdata = datos_prueba, 
                                            type = 'response')

comparacion_regresion <- table(datos_prueba$asistencia_medica, predicciones_regresion_logistica >= 0.6)

verdaderos_positivos_regresion <- comparacion_regresion[2,2]
verdaderos_negativos_regresion <- comparacion_regresion[1,1]
falsos_positivos_regresion <- comparacion_regresion[1,2]
falsos_negativos_regresion <- comparacion_regresion[2,1]

# VP+VN / Total
exactitud_regresion <- (verdaderos_positivos_regresion + verdaderos_negativos_regresion) / sum(comparacion_regresion)

# VP / total positivos
sensibilidad_regresion <- verdaderos_positivos_regresion / (verdaderos_positivos_regresion + falsos_negativos_regresion)

# VP / Total clasificados positivos
precision_regresion <- verdaderos_positivos_regresion / (verdaderos_positivos_regresion + falsos_positivos_regresion )

# VN/ Total Negativos
especificidad_regresion <- verdaderos_negativos_regresion / (verdaderos_negativos_regresion + falsos_positivos_regresion)

paste("* Exactitud Total del modelo Regresion Logistica: ", round(exactitud_regresion * 100, digits = 0), "%")
paste("* Sensibilidad del modelo Regresion Logistica: ", round(sensibilidad_regresion * 100, digits = 0), "%")
paste("* Precision del modelo Regresion Logistica: ", round(precision_regresion * 100, digits = 0), "%")
paste("* Especificidad del modelo Regresion Logistica: ", round(especificidad_regresion * 100, digits = 0), "%")
```


#### Bosques Aleatorios

```{r}

predicciones_bosque_aleatorio <- predict(modelo_bosque_aleatorio, 
                                         newdata = datos_prueba, 
                                         type = 'class')

comparacion_bosque <- table(predicciones_bosque_aleatorio, datos_prueba$asistencia_medica)


verdaderos_positivos_bosque <- comparacion_bosque[2,2]
verdaderos_negativos_bosque <- comparacion_bosque[1,1]
falsos_positivos_bosque <- comparacion_bosque[1,2]
falsos_negativos_bosque <- comparacion_bosque[2,1]

# VP+VN / Total
exactitud_bosque <- (verdaderos_positivos_bosque + verdaderos_negativos_bosque) / sum(comparacion_bosque)

# VP / total positivos
sensibilidad_bosque <- verdaderos_positivos_bosque / (verdaderos_positivos_bosque + falsos_negativos_bosque)

# VP / Total clasificados positivos
precision_bosque <- verdaderos_positivos_bosque / (verdaderos_positivos_bosque + falsos_positivos_bosque )

# VN/ Total Negativos
especificidad_bosque <- verdaderos_negativos_bosque / (verdaderos_negativos_bosque + falsos_positivos_bosque)

paste("* Exactitud Total del modelo Bosque Aleatorio: ", round(exactitud_bosque * 100, digits = 0), "%")
paste("* Sensibilidad del modelo Bosque Aleatorio: ", round(sensibilidad_bosque * 100, digits = 0), "%")
paste("* Precision del modelo Bosque Aleatorio: ", round(precision_bosque * 100, digits = 0), "%")
paste("* Especificidad del modelo Bosque Aleatorio: ", round(especificidad_bosque * 100, digits = 0), "%")

```


# 7. Desarolle al menos 5 conclusiones sobre las clasificaciones de los modelos

- Para el modelo Arbol de decision, en general, los resultados del modelo son considerablemente buenos, a pesar de ser un modelo relativamente sencillo. De las observaciones clasificadas, el 85% se hizo apropiadamente. 

Con respecto al tipo de decisiones que se pueden tomar en este caso, la decision que puede ser mas danina para lsa victimas es que no se envie la asistencia medica en un caso donde se necesita, lo cual puede resultar en la muerte de la victima. La *especificidad* del modelo es del 77%, as铆 que podemos decir que el modelo tiene alrededor de un 23% de posibilidades de cometer este error. 

Alternativamente, se podria enviar la asistencia medica a un accidente que no lo necesite. En este caso, no tenemos afectados directamente, ya que si la victima salio ilesa, no hay mucho trabajo de parte de la asistencia medica, sin embargo, se estarian enviando unidades de asistencia medica a un lugar donde no se necesita, mientras podria estar atendiendo alguna otra emergencia. La *sensitividad* del modelo es del 92%, lo cual quiere decir que el modelo tiene cerca de un 8% probabilidad de cometer este error. Asimismo, la *precisi贸n* es de un 82%, por lo que queda al criterio de los tomadores de decisiones usar o no este modelo.

- Para el modelo de regresion logistica, se crearon variables dummies de los datos que se iban a utilizar (mismos que los del modelo SVN), al igual que el modelo arbol de decision los resultados de este modelo son considerados bastante buenos. La exactitud total de este modelo es de un 85%, lo cual significa que el 85% de las observaciones fueron clasificadas correctamente.

Con respecto al tipo de decisiones que se pueden tomar usando este modelo, al igual que en los demas modelos, la decision que puede afectar mas a las victimas en caso de un accidente, es que no se envie la asistencia medica en un caso donde se requiere, lo cual eventualmente puede resultar en la perdida de la vida de dicha victima. La *especificidad* del modelo es del 89%, as铆 que podemos decir que el modelo tiene alrededor de un 11% de posibilidades de cometer este error.

Asismismo, se puede enviar asistencia medica a un accidente que no lo necesita, lo cual resultaria en ocupar unidades de emergencia que podrian estar atendiendo una emergencia real. La *sensitividad* del modelo es del 82%, lo cual quiere decir que el modelo tiene cerca de un 18% probabilidad de cometer este error. Asimismo, la *precisi贸n* es de un 92%, por lo que queda al criterio de los tomadores de decisiones usar o no este modelo.

- Para el modelo bosque aleatorio, se encuentra que tiene la misma exatitud total que los dos modelos anteriores (Arbol de decison y Regresion Logistica), la cual es de un 85%, asi que al igual que los modelos anteriores se le considera un modelo con buenos resultados.

Con respecto al tipo de decisiones que se pueden tomar usando este modelo, al igual que en los demas modelos, la decision que puede afectar mas a las victimas en caso de un accidente, es que no se envie la asistencia medica en un caso donde se requiere, lo cual eventualmente puede resultar en la perdida de la vida de dicha victima. La *especificidad* del modelo es del 77%, as铆 que podemos decir que el modelo tiene alrededor de un 33% de posibilidades de cometer este error.

Asismismo, se puede enviar asistencia medica a un accidente que no lo necesita, lo cual resultaria en ocupar unidades de emergencia que podrian estar atendiendo una emergencia real. La *sensitividad* del modelo es del 91%, lo cual quiere decir que el modelo tiene cerca de un 9% probabilidad de cometer este error. Asimismo, la *precisi贸n* es de un 82%, por lo que queda al criterio de los tomadores de decisiones usar o no este modelo.

- Del modelo KNN, se concluye que no se puede aplicar correctamente con el dataset asignado, yas que este esta formado unicamente de variables categoricas, mientras que esta modelo necesita variables numericas para funcionar correctamente. 

- Del modelo SVN, se concluye que al igual que el modelo KNN se tienen problemas por el tipo de dataset asignado (formado unicamente de variables categoricas), es este caso en particular se correr el modelo, mas sin embargo no se pudieron graficar los resultados de las predicciones ya que para evaluarlos se necesita un histograma y estos funcionan unicamente con variables numericas.


