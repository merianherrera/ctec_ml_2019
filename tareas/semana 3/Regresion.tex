\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Regresion},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{{#1}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{{#1}}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Regresion}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{}
    \preauthor{}\postauthor{}
    \date{}
    \predate{}\postdate{}
  

\begin{document}
\maketitle

\section{Tarea 3.}\label{tarea-3.}

\section{Regresión lineal}\label{regresion-lineal}

Análisis del Problema

El desempeño de un automóvil se puede medir de diferentes formas.
Algunas comunes son la cantidad de \textbf{caballos de fuerza} y el
\textbf{rendimiento} del mismo, que se puede resumir en cuantas millas
puede recorrer el automóvil por cada galón de combustible que consume.
Para los clientes, potenciales compradores de un automóvil, este
rendimiento es importante pues puede ayudar a tomar una decisión con
respecto a cuál automóvil comprar (si, por ejemplo, el cliente quiere un
auto que rinda por muchas millas y pueda economizar en la compra de
combustible).

Desde este punto de vista, tanto a clientes como a fabricadores de
automóviles, les conviene entender cuál es la relación entre diferentes
características del automóvil y su rendimiento, pues el conocer estas
relaciones les puede ayudar a inferir cuál va a ser la eficiencia del
vehículo a partir de ver los valores de otras características. Para
fabricantes, puede ser importante conocer estas relaciones para saber
cómo hacer cada modelo más eficiente con respecto al anterior.

Entendimiento de los Datos

Con el fin de analizar y tratar de estimar las millas por galón de
diferentes modelos de automóviles, se trabajó con un conjunto de datos
que contiene 398 observaciones y 9 variables:

\begin{itemize}
\tightlist
\item
  mpg (millas por galón): numérica, con un rango de 9 a 46.60.
\item
  cyl (cilindraje): categórica ordinal, con valores posibles de 3, 4, 5,
  6 y 8.
\item
  disp (desplazamiento): numérica, con un rango de 68 a 455.
\item
  hp (caballos de fuerza): numérica, con un rango de 46 a 230 y 6
  valores faltantes.
\item
  weight (peso): numérica, con un rango de 1613 a 5140.
\item
  acc (aceleración): numérica, con un rango de 8 a 24.80.
\item
  model year (año): categórica, con 13 valores diferentes representando
  el año del automóvil.
\item
  origin (origen): categórica, 3 valores posibles: 1, 2, 3.
\item
  model name (nombre del modelo): categórica, con 305 posibles valores.
\end{itemize}

\section{Ejercicios}\label{ejercicios}

\begin{verbatim}
## Loading required package: ggplot2
\end{verbatim}

\begin{verbatim}
## Registered S3 method overwritten by 'GGally':
##   method from   
##   +.gg   ggplot2
\end{verbatim}

\begin{verbatim}
## 
## lessR 3.8.8     feedback: gerbing@pdx.edu     web: lessRstats.com/new
## ---------------------------------------------------------------------
## 1. d <- Read("")           Read text, Excel, SPSS, SAS or R data file
##                            d: default data frame, no need for data=
## 2. l <- Read("", var_labels=TRUE)   Read variable labels into l,
##                            required name for data frame of labels
## 3. Help()                  Get help, and, e.g., Help(Read)
## 4. hs(), bc(), or ca()     All histograms, all bar charts, or both
## 5. Plot(X) or Plot(X,Y)    For continuous and categorical variables
## 6. by1= , by2=             Trellis graphics, a plot for each by1, by2
## 7. reg(Y ~ X, Rmd="eg")    Regression with full interpretative output
## 8. style("gray")           Grayscale theme, + many others available
##    style(show=TRUE)        all color/style options and current values
## 9. getColors()             create many styles of color palettes
## 
## lessR parameter names now use _'s. Names with a period are deprecated.
## Ex:  bin_width  instead of  bin.width
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'dplyr'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:GGally':
## 
##     nasa
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:stats':
## 
##     filter, lag
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:base':
## 
##     intersect, setdiff, setequal, union
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Cargue el archivo auto-mpg\_g.csv en una variable
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{autos <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"auto-mpg_g.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   mpg = col_double(),
##   cyl = col_double(),
##   disp = col_double(),
##   hp = col_double(),
##   weight = col_double(),
##   acc = col_double(),
##   model.year = col_double(),
##   origin = col_double(),
##   model.name = col_character()
## )
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(autos, }\DecValTok{400}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 398 x 9
##      mpg   cyl  disp    hp weight   acc model.year origin model.name       
##    <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl>      <dbl>  <dbl> <chr>            
##  1    18     8   307   130   3504    12         70      1 chevrolet chevel~
##  2    15     8   350   165   3693    12         70      1 buick skylark 320
##  3    18     8   318   150   3436    11         70      1 plymouth satelli~
##  4    16     8   304   150   3433    12         70      1 amc rebel sst    
##  5    17     8   302   140   3449    11         70      1 ford torino      
##  6    15     8   429   198   4341    10         70      1 ford galaxie 500 
##  7    14     8   454   220   4354     9         70      1 chevrolet impala 
##  8    14     8   440   215   4312     9         70      1 plymouth fury iii
##  9    14     8   455   225   4425    10         70      1 pontiac catalina 
## 10    15     8   390   190   3850     9         70      1 amc ambassador d~
## # ... with 388 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Utilizando Ggpairs cree un gráfico de los atributos del dataset,
  observe las correlaciones entre atributos
\end{enumerate}

 \textbf{Histogramas:}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(autos$mpg)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Regresion_files/figure-latex/unnamed-chunk-3-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(autos$weight)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Regresion_files/figure-latex/unnamed-chunk-3-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(autos$disp)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Regresion_files/figure-latex/unnamed-chunk-3-3.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(}\KeywordTok{orderNorm}\NormalTok{(autos$mpg)$x.t, }\DataTypeTok{col=}\StringTok{"#cfbae1"}\NormalTok{,}\DataTypeTok{border=}\StringTok{"#c59fc9"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Regresion_files/figure-latex/unnamed-chunk-3-4.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(}\KeywordTok{orderNorm}\NormalTok{(autos$weight)$x.t, }\DataTypeTok{col=}\StringTok{"#cfbae1"}\NormalTok{,}\DataTypeTok{border=}\StringTok{"#c59fc9"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Regresion_files/figure-latex/unnamed-chunk-3-5.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(}\KeywordTok{orderNorm}\NormalTok{(autos$disp)$x.t, }\DataTypeTok{col=}\StringTok{"#cfbae1"}\NormalTok{,}\DataTypeTok{border=}\StringTok{"#c59fc9"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Regresion_files/figure-latex/unnamed-chunk-3-6.pdf}

 \textbf{Preparacion de los datos:}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Ya que tenemos valores en 0 dentro de la variable caballos de fuerza, necesitamos excluir esos datos para no afectar nuestros calculos.}
\NormalTok{autos <-}\StringTok{ }\NormalTok{autos[!(autos$hp ==}\StringTok{ }\DecValTok{0}\NormalTok{),]}

\CommentTok{# Llenar los valores nulos en la columna caballos de fuerza}
\NormalTok{media_hp =}\StringTok{ }\KeywordTok{median}\NormalTok{(autos$hp)}
\NormalTok{autos$hp[}\KeywordTok{is.na}\NormalTok{(autos$hp)] <-}\StringTok{ }\NormalTok{media_hp}

\CommentTok{# Dividir los valores de la columna modelo para extraer solo el fabricante, ya que al tener 305 modelos estabamos perdiendo variabilidad en los datos}
\NormalTok{autos <-}\StringTok{ }\NormalTok{autos %>%}\StringTok{ }\KeywordTok{separate}\NormalTok{(model.name, }
                \KeywordTok{c}\NormalTok{(}\StringTok{"manufacturer"}\NormalTok{))}

\CommentTok{# Normalizar las variables que vamos a usar}
\NormalTok{mpg_normalized <-}\StringTok{ }\KeywordTok{orderNorm}\NormalTok{(autos$mpg)$x.t}
\NormalTok{weight_normalized <-}\StringTok{ }\KeywordTok{orderNorm}\NormalTok{(autos$weight)$x.t}
\NormalTok{disp_normalized <-}\StringTok{ }\KeywordTok{orderNorm}\NormalTok{(autos$disp)$x.t}
\NormalTok{hp_normalized <-}\StringTok{ }\KeywordTok{orderNorm}\NormalTok{(autos$hp)$x.t}

\NormalTok{autos$mpg <-}\StringTok{ }\NormalTok{mpg_normalized}
\NormalTok{autos$weight <-}\StringTok{ }\NormalTok{weight_normalized}
\NormalTok{autos$disp <-}\StringTok{ }\NormalTok{disp_normalized}
\NormalTok{autos$hp <-}\StringTok{ }\NormalTok{hp_normalized}
\KeywordTok{head}\NormalTok{(autos, }\DecValTok{400}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 392 x 9
##       mpg   cyl  disp    hp weight   acc model.year origin manufacturer
##     <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl>      <dbl>  <dbl> <chr>       
##  1 -0.561     8 0.870 0.705  0.587    12         70      1 chevrolet   
##  2 -1.02      8 1.18  1.33   0.738    12         70      1 buick       
##  3 -0.561     8 0.967 1.06   0.542    11         70      1 plymouth    
##  4 -0.843     8 0.789 1.06   0.535    12         70      1 amc         
##  5 -0.713     8 0.713 0.816  0.564    11         70      1 ford        
##  6 -1.02      8 2.02  1.84   1.35     10         70      1 ford        
##  7 -1.24      8 2.28  2.20   1.37      9         70      1 chevrolet   
##  8 -1.24      8 2.16  2.07   1.31      9         70      1 plymouth    
##  9 -1.24      8 2.49  2.37   1.52     10         70      1 pontiac     
## 10 -1.02      8 1.56  1.73   0.861     9         70      1 amc         
## # ... with 382 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(autos$mpg)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Regresion_files/figure-latex/unnamed-chunk-5-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(autos$weight)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Regresion_files/figure-latex/unnamed-chunk-5-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(autos$disp)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Regresion_files/figure-latex/unnamed-chunk-5-3.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(autos$hp)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Regresion_files/figure-latex/unnamed-chunk-5-4.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggpairs}\NormalTok{(autos,}\DataTypeTok{columns =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{Regresion_files/figure-latex/unnamed-chunk-6-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Separe los datos en 2 conjuntos, uno de entrenamiento y otro de
  pruebas. Normalmente se trabaja utilizando un 70-80\% de los datos
  para entrenamiento y el resto para pruebas.
\end{enumerate}

Recuerde fijar una semilla para que el documento sea reproducible.

Pista:
\url{https://www.rdocumentation.org/packages/caTools/versions/1.17.1/topics/sample.split}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{124}\NormalTok{) }\CommentTok{# reproducibilidad}

\NormalTok{y =}\StringTok{  }\NormalTok{dplyr::}\KeywordTok{pull}\NormalTok{(autos, mpg)}

\NormalTok{autos$dividir_datos <-}\StringTok{ }\KeywordTok{sample.split}\NormalTok{(y, }\DataTypeTok{SplitRatio=}\FloatTok{0.70}\NormalTok{)}
\KeywordTok{head}\NormalTok{(autos, }\DecValTok{400}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 392 x 10
##       mpg   cyl  disp    hp weight   acc model.year origin manufacturer
##     <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl>      <dbl>  <dbl> <chr>       
##  1 -0.561     8 0.870 0.705  0.587    12         70      1 chevrolet   
##  2 -1.02      8 1.18  1.33   0.738    12         70      1 buick       
##  3 -0.561     8 0.967 1.06   0.542    11         70      1 plymouth    
##  4 -0.843     8 0.789 1.06   0.535    12         70      1 amc         
##  5 -0.713     8 0.713 0.816  0.564    11         70      1 ford        
##  6 -1.02      8 2.02  1.84   1.35     10         70      1 ford        
##  7 -1.24      8 2.28  2.20   1.37      9         70      1 chevrolet   
##  8 -1.24      8 2.16  2.07   1.31      9         70      1 plymouth    
##  9 -1.24      8 2.49  2.37   1.52     10         70      1 pontiac     
## 10 -1.02      8 1.56  1.73   0.861     9         70      1 amc         
## # ... with 382 more rows, and 1 more variable: dividir_datos <lgl>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{autos_training=}\KeywordTok{subset}\NormalTok{(autos, autos$dividir_datos==}\OtherTok{TRUE}\NormalTok{)}
\KeywordTok{head}\NormalTok{(autos_training, }\DecValTok{400}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 274 x 10
##       mpg   cyl  disp    hp weight   acc model.year origin manufacturer
##     <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl>      <dbl>  <dbl> <chr>       
##  1 -0.561     8 0.870 0.705  0.587    12         70      1 chevrolet   
##  2 -0.561     8 0.967 1.06   0.542    11         70      1 plymouth    
##  3 -0.843     8 0.789 1.06   0.535    12         70      1 amc         
##  4 -0.713     8 0.713 0.816  0.564    11         70      1 ford        
##  5 -1.02      8 2.02  1.84   1.35     10         70      1 ford        
##  6 -1.24      8 2.28  2.20   1.37      9         70      1 chevrolet   
##  7 -1.24      8 2.16  2.07   1.31      9         70      1 plymouth    
##  8 -1.02      8 1.56  1.73   0.861     9         70      1 amc         
##  9 -1.02      8 1.53  1.42   0.625    10         70      1 dodge       
## 10 -1.24      8 1.06  1.29   0.657     8         70      1 plymouth    
## # ... with 264 more rows, and 1 more variable: dividir_datos <lgl>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{autos_testing=}\KeywordTok{subset}\NormalTok{(autos, autos$dividir_datos==}\OtherTok{FALSE}\NormalTok{)}
\KeywordTok{head}\NormalTok{(autos_testing, }\DecValTok{400}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 118 x 10
##       mpg   cyl   disp     hp weight   acc model.year origin manufacturer
##     <dbl> <dbl>  <dbl>  <dbl>  <dbl> <dbl>      <dbl>  <dbl> <chr>       
##  1 -1.02      8  1.18   1.33   0.738    12         70      1 buick       
##  2 -1.24      8  2.49   2.37   1.52     10         70      1 pontiac     
##  3 -0.157     6  0.219 -0.393 -0.245    16         70      1 ford        
##  4  0.225     4 -0.549 -0.321 -0.121    18         70      2 peugeot     
##  5 -2.57      8  1.47   2.07   1.73     14         70      1 ford        
##  6 -2.23      8  0.967  1.97   1.46     14         70      1 dodge       
##  7 -0.843     6  0.284  0.348  0.549    16         71      1 plymouth    
##  8 -1.24      8  1.36   1.22   1.13     14         71      1 ford        
##  9 -1.24      8  0.967  1.06   1.05     13         71      1 plymouth    
## 10 -1.57      8  1.73   1.52   2.67     12         71      1 pontiac     
## # ... with 108 more rows, and 1 more variable: dividir_datos <lgl>
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Cree un modelo de regresion lineal utilizando el atributo mpg como la
  variable objetivo y en base a las correlaciones observadas en el
  gráfico del punto 2 escoja al menos dos atributos para usarlos como
  variables predictoras para el modelo.
\end{enumerate}

Pista:
\url{https://www.rdocumentation.org/packages/lessR/versions/1.9.8/topics/reg}

Nota: Al crear el modelo utilice el conjunto de datos de entrenamiento
definido en el punto 3.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{regresion_data_training =}\StringTok{ }\NormalTok{lessR::}\KeywordTok{reg}\NormalTok{(mpg ~}\StringTok{ }\NormalTok{hp +}\StringTok{ }\NormalTok{weight, }
           \DataTypeTok{data=}\NormalTok{autos_training, }\DataTypeTok{dframe=}\NormalTok{autos_training, }
           \DataTypeTok{sig.digits=}\DecValTok{4}\NormalTok{, }\DataTypeTok{res.rows=}\OtherTok{NULL}\NormalTok{, }\DataTypeTok{results=}\StringTok{"brief"}\NormalTok{, }\DataTypeTok{scatter.cor=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Regresion_files/figure-latex/unnamed-chunk-10-1.pdf}
\includegraphics{Regresion_files/figure-latex/unnamed-chunk-10-2.pdf}
\includegraphics{Regresion_files/figure-latex/unnamed-chunk-10-3.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{regresion_data_training}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## >>> Suggestion
## # Create an R markdown file for interpretative output with  Rmd = "file_name"
## lessR::reg(mpg ~ hp + weight, data=autos_training, dframe=autos_training, sig.digits=4, res.rows=NULL, results="brief", scatter.cor=TRUE, Rmd="eg")  
## 
## 
##   BACKGROUND
## 
## Data Frame:  autos_training 
##  
## Response Variable: mpg 
## Predictor Variable 1: hp 
## Predictor Variable 2: weight 
##  
## Number of cases (rows) of data:  274 
## Number of cases retained for analysis:  274 
## 
## 
##   BASIC ANALYSIS
## 
##                Estimate      Std Err  t-value  p-value     Lower 95%     Upper 95% 
## (Intercept) -0.022556968  0.029985205   -0.752    0.453   -0.081590530   0.036476594 
##          hp -0.386720470  0.058815184   -6.575    0.000   -0.502513236   -0.270927704 
##      weight -0.523137171  0.058216643   -8.986    0.000   -0.637751555   -0.408522787 
## 
## 
## Standard deviation of residuals:  0.496172883 for 271 degrees of freedom 
##  
## R-squared:  0.751    Adjusted R-squared:  0.749    PRESS R-squared:  0.744 
## 
## Null hypothesis that all population slope coefficients are 0:
##   F-statistic: 408.693     df: 2 and 271     p-value:  0.000 
## 
## 
##                  df         Sum Sq        Mean Sq        F-value   p-value 
##        hp         1  181.350627702  181.350627702  736.636124551     0.000 
##    weight         1   19.879382420   19.879382420   80.748941484     0.000 
## Model             2  201.230010122  100.615005061  408.692533018     0.000 
##  
## Residuals       271   66.716820516    0.246187530 
##  
## mpg             273  267.946830638    0.981490222 
## 
## 
##   RELATIONS AMONG THE VARIABLES
## 
##            mpg    hp weight 
##      mpg  1.00 -0.82  -0.84 
##       hp -0.82  1.00   0.85 
##   weight -0.84  0.85   1.00 
## 
## 
##          Tolerance       VIF 
##       hp     0.275     3.639 
##   weight     0.275     3.639 
## 
## 
##   hp weight    R2adj    X's 
##    1      1    0.749      2 
##    0      1    0.710      1 
##    1      0    0.676      1 
##  
## [based on Thomas Lumley's leaps function from the leaps package] 
##  
## 
## 
##   RESIDUALS AND INFLUENCE
## 
## Data, Fitted, Residual, Studentized Residual, Dffits, Cook's Distance 
##    [sorted by Cook's Distance] 
##    [res_rows = 20, out of 274 rows of data, or do res_rows="all"] 
## ------------------------------------------------------------------------------------------------------------ 
##                 hp       weight          mpg       fitted        resid       rstdnt       dffits       cooks 
##    17 -2.801341806 -1.854880931  0.334617707  2.031136415 -1.696518708 -3.560445378 -0.707883338 0.160130000 
##    85  2.667860800  1.264343200 -0.842530466 -1.715698276  0.873167810  1.809064702  0.396252089 0.051900000 
##   227 -1.216174186  0.137563705  1.466567896  0.375797797  1.090770099  2.247406696  0.387443222 0.049300000 
##   272 -2.046446427 -0.912846734  2.319716215  1.246389815  1.073326400  2.211807923  0.387120575 0.049250000 
##   110 -0.837991240  0.527330098 -1.019663578  0.025645422 -1.045309001 -2.151219528 -0.365675026 0.043980000 
##    23  1.787904922  1.974313947 -3.017995210 -1.746813414 -1.271181797 -2.614302699 -0.363397920 0.043090000 
##    45 -1.854880931 -0.625250571  0.025515524  1.021855273 -0.996339748 -2.050858685 -0.360485537 0.042810000 
##   225 -1.395550582 -1.014314788  2.667860800  1.047756778  1.620104022  3.345387610  0.361437568 0.041970000 
##    90  1.624234831  0.713030358 -2.234574559 -1.023694510 -1.210880049 -2.489089609 -0.358104185 0.041940000 
##    40 -1.052389541 -3.017995210  1.338720814  1.963249088 -0.624528273 -1.305930271 -0.354469954 0.041770000 
##   111 -0.837991240  0.284429277 -1.019663578  0.152715870 -1.172379449 -2.408466333 -0.348217766 0.039710000 
##    86 -2.197429002 -1.728104641  0.656580980  1.731269582 -1.074688602 -2.206257068 -0.334306571 0.036730000 
##   268 -0.392543755  0.199030117  1.772353607  0.025127685  1.747225922  3.613987243  0.331122883 0.034990000 
##    41 -1.700385039 -1.891750938  0.455353474  1.624661968 -1.169308494 -2.397703825 -0.315480544 0.032600000 
##    22  1.891750938  1.421345696 -2.569718544 -1.497694547 -1.072023997 -2.195864981 -0.299149321 0.029420000 
##   232  0.729576886  0.083011697  1.103707360 -0.348125788  1.451833149  2.982924004  0.295497260 0.028280000 
##   229 -1.216174186 -1.757219474  2.491439974  1.367029310  1.124410664  2.302535992  0.293281753 0.028220000 
##   143 -2.046446427 -1.170672906  0.656580980  1.381268269 -0.724687288 -1.482075634 -0.235091187 0.018340000 
##   216 -0.652629890 -0.879491463  2.073046643  0.689923046  1.383123597  2.832725484  0.229427699 0.017100000 
##   144 -1.911194085 -2.163088790  1.103707360  1.848133058 -0.744425697 -1.520065176 -0.223057542 0.016510000 
## 
## 
##   FORECASTING ERROR
## 
## Data, Predicted, Standard Error of Forecast, 95% Prediction Intervals 
##    [sorted by lower bound of prediction interval] 
##    [to see all intervals do pred_rows="all"] 
## ----------------------------------------------------------------------------------------------------------- 
##                 hp       weight          mpg         pred          sf       pi:lwr       pi:upr       width 
##   139  1.196370103  1.189872033 -1.019663578 -1.107684066 0.498579506 -2.089265616 -0.126102516 1.963163100 
##    12  2.369509348  0.238227261 -1.236467101 -1.063520272 0.513174571 -2.073835948 -0.053204596 2.020631352 
##   166  0.937307300  1.338720814 -0.842530466 -1.085367508 0.498947313 -2.067673181 -0.103061834 1.964611347 
## ... 
##    15  0.140783837 -0.031896353 -0.560609736 -0.060314792 0.497169857 -1.039121087  0.918491504 1.957612591 
##    14  0.047854676  0.019135735 -0.060629921 -0.051073965 0.497081757 -1.029706813  0.927558883 1.957265696 
##   270 -0.118271653  0.137563705  0.455353474 -0.048783586 0.497300669 -1.027847419  0.930280246 1.958127664 
## ... 
##   240 -1.700385039 -2.369509348  1.338720814  1.874595151 0.502498434  0.885298186  2.863892116 1.978593931 
##    40 -1.052389541 -3.017995210  1.338720814  1.963249088 0.512913969  0.953446473  2.973051702 2.019605229 
##    17 -2.801341806 -1.854880931  0.334617707  2.031136415 0.505518549  1.035893581  3.026379250 1.990485669 
## 
## 
## ---------------------------------- 
## Plot 1: Distribution of Residuals 
## Plot 2: Residuals vs Fitted Values 
## Plot 3: ScatterPlot Matrix 
## ----------------------------------
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Realice predicciones utilizando el conjunto de pruebas y evalue el
  resultado con la métrica MSE.
\end{enumerate}

Pista:
\url{https://www.rdocumentation.org/packages/mltools/versions/0.3.5/topics/mse}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# mse(preds = NULL, actuals = NULL, weights = 1, na.rm = FALSE)}
\CommentTok{# mse(actual, predicted)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Opcional
\end{enumerate}

6.a Pruebe varios modelos que utilicen diferentes variables y comparar
los resultados obtenidos

6.b Investigar como implementar en R las técnicas de preprocesado y
normalización vistas en clase y aplicarlas a los datos antes de pasarlos
al modelo.


\end{document}
